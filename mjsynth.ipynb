{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG Dataset\n",
    "\n",
    "The [MJSynth](https://www.robots.ox.ac.uk/~vgg/data/text/) dataset consists of 9 million images covering 90k English words, and includes the training, validation and test splits. It was produced by the Visual Geometry Group at the University of Oxford.\n",
    "\n",
    "Authors: Max Jaderberg, Karen Simonyan, Andrea Vedaldi, Andrew Zisserman\n",
    "\n",
    "Publications: [ECCV 2014](https://www.robots.ox.ac.uk/~vgg/publications/2014/Jaderberg14/), [NeurIPS 2014](https://www.robots.ox.ac.uk/~vgg/publications/2014/Jaderberg14c/), [IJCV 2016](http://www.robots.ox.ac.uk/~vgg/publications/2016/Jaderberg16/)\n",
    "\n",
    "Size: 15.79 GB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset\n",
    "The dataset was loaded using the Kaggle API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SynthText in the Wild Dataset\n",
    "-----------------------------\n",
    "Ankush Gupta, Andrea Vedaldi, and Andrew Zisserman\n",
    "Visual Geometry Group, University of Oxford, 2016\n",
    "\n",
    "\n",
    "Data format:\n",
    "------------\n",
    "\n",
    "SynthText.zip (size = 42074172 bytes (41GB)) contains 858,750 synthetic\n",
    "scene-image files (.jpg) split into 200 directories, with \n",
    "7,266,866 word-instances, and 28,971,487 characters.\n",
    "\n",
    "Ground-truth annotations are contained in the file \"gt.mat\" (Matlab format).\n",
    "The file \"gt.mat\" contains the following cell-arrays, each of size 1x858750:\n",
    "\n",
    "  1. imnames :  names of the image files\n",
    "\n",
    "  2. wordBB  :  word-level bounding-boxes for each image, represented by\n",
    "                tensors of size 2x4xNWORDS_i, where:\n",
    "                   - the first dimension is 2 for x and y respectively,\n",
    "                   - the second dimension corresponds to the 4 points\n",
    "                     (clockwise, starting from top-left), and\n",
    "                   -  the third dimension of size NWORDS_i, corresponds to\n",
    "                      the number of words in the i_th image.\n",
    "\n",
    "  3. charBB  : character-level bounding-boxes,\n",
    "               each represented by a tensor of size 2x4xNCHARS_i\n",
    "               (format is same as wordBB's above)\n",
    "\n",
    "  4. txt     : text-strings contained in each image (char array).\n",
    "               \n",
    "               Words which belong to the same \"instance\", i.e.,\n",
    "               those rendered in the same region with the same font, color,\n",
    "               distortion etc., are grouped together; the instance\n",
    "               boundaries are demarcated by the line-feed character (ASCII: 10)\n",
    "\n",
    "               A \"word\" is any contiguous substring of non-whitespace\n",
    "               characters.\n",
    "\n",
    "               A \"character\" is defined as any non-whitespace character.\n",
    "\n",
    "\n",
    "For any questions or comments, contact Ankush Gupta at:\n",
    "removethisifyouarehuman-ankush@robots.ox.ac.uk"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
